{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saani/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_forum_post(text_dir, filename):\n",
    "    \"\"\"\n",
    "    Reads the contents of a forum post from the cadec/text directory.\n",
    "    Args:\n",
    "        text_dir (str): Path to the text directory (e.g., 'cadec/text')\n",
    "        filename (str): Name of the file to read (e.g., 'ARTHROTEC.1.txt')\n",
    "    Returns:\n",
    "        str: The contents of the forum post as a string.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(text_dir, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_text_with_bio(text, model_name=\"d4data/biomedical-ner-all\"):\n",
    "    \"\"\"\n",
    "    Uses a Hugging Face NER pipeline to label each word in the text with BIO/IOB format.\n",
    "    Args:\n",
    "        text (str): The input forum post text.\n",
    "        model_name (str): The Hugging Face model to use.\n",
    "    Returns:\n",
    "        list of dict: Each dict contains 'word', 'entity', 'score', 'start', 'end'.\n",
    "    \"\"\"\n",
    "    # Load the model and tokenizer\n",
    "    ner_pipeline = pipeline(\"ner\", model=model_name, tokenizer=model_name, aggregation_strategy=\"simple\")\n",
    "    # Run the pipeline on the text\n",
    "    ner_results = ner_pipeline(text)\n",
    "    return ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_entity_label(entity_label):\n",
    "    \"\"\"\n",
    "    Maps the model's entity label to one of the four required categories: ADR, Drug, Disease, Symptom.\n",
    "    Returns None if the label should be ignored.\n",
    "    \"\"\"\n",
    "    # Lowercase for robustness\n",
    "    label = entity_label.lower()\n",
    "    # Mapping based on typical biomedical NER conventions and CADEC .ann files\n",
    "    if label in [\"medication\", \"drug\",\"therapeutic_procedure\"]:\n",
    "        return \"Drug\"\n",
    "    elif label in [\"disease_disorder\", \"disease\"]:\n",
    "        return \"Disease\"\n",
    "    elif label in [\"sign_symptom\", \"symptom\"]:\n",
    "        return \"Symptom\"\n",
    "    elif label in [\"adr\", \"adverse_event\",\"sign_symptom\", \"adverse drug reaction\", \"adverse reaction\",\"detailed_description\"]:\n",
    "        return \"ADR\"\n",
    "    # Add more mappings if needed based on model output\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ner_to_ann_format(ner_results, label_prefix=\"T\"):\n",
    "    \"\"\"\n",
    "    Converts NER results to the .ann label format used in 'cadec/original',\n",
    "    mapping model labels to the four required categories.\n",
    "    Args:\n",
    "        ner_results (list of dict): Output from the NER pipeline.\n",
    "        label_prefix (str): Prefix for the tag (default 'T').\n",
    "    Returns:\n",
    "        list of str: Each string is a line in the .ann format: Tag<TAB>Label Start End<TAB>Text\n",
    "    \"\"\"\n",
    "    ann_lines = []\n",
    "    idx = 1\n",
    "    for entity in ner_results:\n",
    "        mapped_label = map_entity_label(entity['entity_group'])\n",
    "        if mapped_label is None:\n",
    "            continue  # Skip entities not in the required categories\n",
    "        tag = f\"{label_prefix}{idx}\"\n",
    "        start = entity['start']\n",
    "        end = entity['end']\n",
    "        text = entity['word']\n",
    "        ann_line = f\"{tag}\\t{mapped_label} {start} {end}\\t{text}\"\n",
    "        ann_lines.append(ann_line)\n",
    "        idx += 1\n",
    "    return ann_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_ner_results(ner_results, text):\n",
    "    \"\"\"\n",
    "    Postprocesses the NER results to merge subword tokens (e.g., 'dr' + '##owsy' -> 'drowsy'),\n",
    "    reconstructing full entities and correcting their spans.\n",
    "    Args:\n",
    "        ner_results (list of dict): Output from the NER pipeline.\n",
    "        text (str): The original input text.\n",
    "    Returns:\n",
    "        list of dict: Cleaned NER results with merged entities.\n",
    "    \"\"\"\n",
    "    if not ner_results:\n",
    "        return []\n",
    "    merged_results = []\n",
    "    prev = None\n",
    "    for entity in ner_results:\n",
    "        # If this is the first entity, just add it\n",
    "        if prev is None:\n",
    "            prev = entity.copy()\n",
    "            continue\n",
    "        # If the current entity is contiguous with the previous and has the same label, merge them\n",
    "        if (entity['entity_group'] == prev['entity_group'] and entity['start'] == prev['end']):\n",
    "            # Merge the words and update the end position\n",
    "            prev['word'] += entity['word'].replace('##', '')\n",
    "            prev['end'] = entity['end']\n",
    "        else:\n",
    "            # Finalize the previous entity\n",
    "            # Re-extract the text from the original input to avoid tokenization artifacts\n",
    "            prev['word'] = text[prev['start']:prev['end']]\n",
    "            merged_results.append(prev)\n",
    "            prev = entity.copy()\n",
    "    # Add the last entity\n",
    "    if prev is not None:\n",
    "        prev['word'] = text[prev['start']:prev['end']]\n",
    "        merged_results.append(prev)\n",
    "    return merged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Forum Post ---\n",
      "I feel a bit drowsy & have a little blurred vision, so far no gastric problems.\n",
      "I've been on Arthrotec 50 for over 10 years on and off, only taking it when I needed it.\n",
      "Due to my arthritis getting progressively worse, to the point where I am in tears with the agony, gp's started me on 75 twice a day and I have to take it.\n",
      "every day for the next month to see how I get on, here goes.\n",
      "So far its been very good, pains almost gone, but I feel a bit weird, didn't have that when on 50.\n",
      "\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BIO/IOB Labelling Results ---\n",
      "Text: 'drowsy' | Label: Sign_symptom | Score: 1.00 | Start: 13 | End: 19\n",
      "Text: 'blurred' | Label: Sign_symptom | Score: 0.78 | Start: 36 | End: 43\n",
      "Text: 'Art' | Label: Detailed_description | Score: 0.97 | Start: 93 | End: 96\n",
      "Text: 'hrotec' | Label: Therapeutic_procedure | Score: 0.55 | Start: 96 | End: 102\n",
      "Text: '50' | Label: Dosage | Score: 0.30 | Start: 103 | End: 105\n",
      "Text: 'over 10 years' | Label: Duration | Score: 1.00 | Start: 110 | End: 123\n",
      "Text: 'arthritis' | Label: Disease_disorder | Score: 1.00 | Start: 179 | End: 188\n",
      "Text: '75' | Label: Lab_value | Score: 0.97 | Start: 286 | End: 288\n",
      "Text: 'twice a day' | Label: Frequency | Score: 0.84 | Start: 289 | End: 300\n",
      "Text: 'every day' | Label: Frequency | Score: 1.00 | Start: 324 | End: 333\n",
      "Text: 'for' | Label: Frequency | Score: 0.58 | Start: 334 | End: 337\n",
      "Text: 'the next month' | Label: Duration | Score: 0.78 | Start: 338 | End: 352\n",
      "Text: 'pains' | Label: Sign_symptom | Score: 1.00 | Start: 412 | End: 417\n",
      "Text: 't have that' | Label: Detailed_description | Score: 0.65 | Start: 460 | End: 471\n",
      "---------------------------------\n",
      "\n",
      "--- Converted to .ann Format ---\n",
      "T1\tSymptom 13 19\tdrowsy\n",
      "T2\tSymptom 36 43\tblurred\n",
      "T3\tADR 93 96\tArt\n",
      "T4\tDrug 96 102\throtec\n",
      "T5\tDisease 179 188\tarthritis\n",
      "T6\tSymptom 412 417\tpains\n",
      "T7\tADR 460 471\tt have that\n",
      "\n",
      "Predictions written to predicted.ann for evaluation.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example: process a single file for demonstration\n",
    "    example_filename = \"ARTHROTEC.1.txt\"  # You can change this to any file in cadec/text\n",
    "    text_dir = os.path.join(\"cadec\", \"text\")\n",
    "    # Step 1: Read the forum post\n",
    "    forum_post = read_forum_post(text_dir, example_filename)\n",
    "    print(\"--- Forum Post ---\")\n",
    "    print(forum_post)\n",
    "    print(\"------------------\")\n",
    "    # Step 2: Run the model and postprocess the results\n",
    "    ner_results = label_text_with_bio(forum_post)\n",
    "    ner_results = postprocess_ner_results(ner_results, forum_post)\n",
    "    print(\"\\n--- BIO/IOB Labelling Results ---\")\n",
    "    for entity in ner_results:\n",
    "        print(f\"Text: '{entity['word']}' | Label: {entity['entity_group']} | Score: {entity['score']:.2f} | Start: {entity['start']} | End: {entity['end']}\")\n",
    "    print(\"---------------------------------\")\n",
    "    # Step 3: Convert to .ann format (after postprocessing and mapping)\n",
    "    ann_lines = convert_ner_to_ann_format(ner_results)\n",
    "    print(\"\\n--- Converted to .ann Format ---\")\n",
    "    for line in ann_lines:\n",
    "        print(line)\n",
    "    # Write predictions to a file for evaluation in step 3\n",
    "    with open(\"predicted.ann\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in ann_lines:\n",
    "            f.write(line + \"\\n\")\n",
    "    print(\"\\nPredictions written to predicted.ann for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
